# Phase 14.1: CORTEX Thinking Frameworks - Research

**Researched:** 2026-02-20
**Domain:** Structured thinking protocols / prompt engineering for adaptive reasoning
**Confidence:** HIGH

<user_constraints>
## User Constraints (from CONTEXT.md)

### Locked Decisions
- **Integration point:** Dedicated skill file `skills/cortex/SKILL.md` with auto-trigger. Consistent with existing Megazord pattern (all features are skills). No additional hooks needed. All spawned agents inherit CORTEX through the plugin.
- **Activation behavior:** Always-on: classify every task through Cynefin, then scale response. Simple tasks get classification only (minimal overhead), no framework output shown. Complicated+ tasks trigger structured thinking frameworks with visible output. No user override mechanism.
- **Classification visibility:** Silent on Simple tasks. Visible header on Complicated+ tasks showing domain, key signals, frameworks being applied. Format: `CORTEX -> Complicated | 3 files, known pattern, 1 new interface | Applying: Inversion + Ladder of Inference`
- **Thinking output format:** Detailed reasoning inside collapsible `<details>` blocks (GSD style). User sees only the CORTEX header; expanding reveals full framework analysis. Claude's Discretion on exact structure per framework.
- **Framework scope (mandatory base from untools.co):** Inversion (pre-mortem), Ladder of Inference (assumption chain), Second-Order Thinking (consequence trace), First Principles, Abstraction Laddering, Iceberg Model, Issue Tree, Ishikawa. Claude's Discretion to complement with 5 Whys and MECE when they fit naturally.

### Claude's Discretion
- **Classification thresholds:** Design a combined signal heuristic weighing LOC estimate, file count, new dependencies, pattern familiarity, side-effects, external system interaction. Not purely numeric. CORTEX-05 asks for "LOC ranges, module counts, API surface metrics" as primary signals with qualitative override.
- **Thinking output structure:** Some frameworks may benefit from rigid templates (Issue Tree), others from flowing analysis (First Principles).
- **File artifacts:** Persist analysis to file when it adds value (likely for Complex/Chaotic tasks that produce reusable insights).
- **Iceberg Model triggers (CORTEX-03):** Detection mechanism for "recurring area" -- may use SUMMARY.md from previous executions, git history, or contextual awareness of recently-modified areas.
- **Issue Tree + Ishikawa in debug (CORTEX-04):** When to activate in debug mode -- always-on for `/mz:debug` may be overkill for trivial bugs.
- **First Principles + Abstraction Laddering (CORTEX-02):** Activated for Complex domain tasks replacing ad-hoc brainstorming.

### Deferred Ideas (OUT OF SCOPE)
- Beads pattern (steveyegge/beads) integration into CORTEX -- explicitly deferred to v1.2+ per REQUIREMENTS.md (CRTX-BEADS-01)
</user_constraints>

<phase_requirements>
## Phase Requirements

| ID | Description | Research Support |
|----|-------------|-----------------|
| CORTEX-01 | Enhanced challenge block format -- Inversion (pre-mortem), Ladder of Inference (assumption chain), Second-Order Thinking (consequence trace) for Complicated+ tasks | Framework definitions from untools.co verified. Current challenge block structure in `agents/mz-executor.md` already has INVERSION/ASSUMPTIONS/SECOND-ORDER fields. Enhancement = explicit framework naming, structured sub-fields per framework, and the `<details>` collapsible format. |
| CORTEX-02 | Complex domain structured brainstorm -- First Principles decomposition + Abstraction Laddering replacing ad-hoc mini-brainstorm | Both frameworks verified from untools.co. Current `<complex-analysis>` block in executor already has FIRST-PRINCIPLES and ABSTRACTION fields. Enhancement = expand with proper why/how laddering, Socratic questioning prompts, and explicit alternatives with tradeoffs. |
| CORTEX-03 | Iceberg Model systems analysis -- triggered when task touches area flagged in previous SUMMARY as modified/rejected | Iceberg Model four layers (Events/Patterns/Structures/Mental Models) verified. Current `<iceberg>` block in executor already has these fields. Enhancement = move to skill file, add detection mechanism for recurring areas using SUMMARY.md scanning. |
| CORTEX-04 | Debug root-cause analysis -- Issue Tree (MECE decomposition) + Ishikawa cause categories | Issue Tree and Ishikawa verified from untools.co. Current debug skill (`skills/debug/SKILL.md`) already has Issue Tree and Ishikawa in ROOT CAUSE phase (Step 5). Enhancement = formalize Ishikawa categories for software (Code/Data/Environment/Dependencies/Timing/State already defined), add CORTEX integration for complexity-aware debug depth. |
| CORTEX-05 | Concrete classification signal heuristics -- LOC ranges, module counts, API surface metrics replacing vague descriptions | Current executor has a heuristic table (Clear/Complicated/Complex/Chaotic) with LOC ranges and module counts. Enhancement = move to dedicated skill file, add more concrete signals (new dependencies, pattern familiarity, side-effects, external system interaction), make reproducible. |
</phase_requirements>

## Summary

Phase 14.1 elevates CORTEX from an inline section embedded within `agents/mz-executor.md` into a first-class Megazord skill at `skills/cortex/SKILL.md`. The key architectural insight is that CORTEX functionality already exists in the codebase -- the challenge block, complex analysis block, iceberg analysis, and classification heuristics are all defined inline in the executor agent. The debug skill already has Issue Tree and Ishikawa. This phase is primarily a **refactoring and enhancement** operation, not a build-from-scratch effort.

The work decomposes into three logical units: (1) extract the existing CORTEX protocol from the executor into a dedicated skill with enhanced framework content, (2) enhance the debug skill with CORTEX-aware depth control, and (3) update the executor agent and go skill to reference the new CORTEX skill instead of containing the protocol inline.

**Primary recommendation:** Extract CORTEX from `agents/mz-executor.md` into `skills/cortex/SKILL.md` as an auto-trigger skill. Enhance each framework block with the verified untools.co methodology (documented below). Update executor and debug skill to reference the CORTEX skill. Do NOT create a hooks-based enforcement mechanism -- the skill auto-trigger pattern is the established Megazord convention and the user has locked this decision.

## Standard Stack

### Core

This phase has no external library dependencies. All work is in Markdown skill files and agent definitions -- pure prompt engineering.

| Component | Location | Purpose | Why Standard |
|-----------|----------|---------|--------------|
| SKILL.md | `skills/cortex/SKILL.md` | CORTEX skill definition with auto-trigger | Megazord convention: all features are skills in `skills/` |
| mz-executor.md | `agents/mz-executor.md` | Agent definition referencing CORTEX skill | Existing pattern: executor reads from skill files |
| debug SKILL.md | `skills/debug/SKILL.md` | Debug skill with CORTEX integration | Existing file: enhance Step 5 |
| go SKILL.md | `skills/go/SKILL.md` | Orchestrator with CORTEX flag forwarding | Existing file: already forwards `cortex_enabled` |
| executor.md | `skills/go/executor.md` | Execution protocol referencing CORTEX | Existing file: already documents CORTEX flag forwarding |

### Supporting

| Component | Location | Purpose | When to Use |
|-----------|----------|---------|-------------|
| config.ts | `src/lib/config.ts` | Config schema with `quality.cortex` boolean | Already exists -- no changes needed |
| presets.md | `skills/init/presets.md` | Preset profiles referencing CORTEX | Already exists -- no changes needed |

### Alternatives Considered

| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| Skill file (SKILL.md) | Hook-based CORTEX (scripts/) | User locked decision: skill pattern, not hooks |
| Single monolithic CORTEX skill | Multiple skill files per framework | Over-engineering -- single file with sections is simpler and matches existing skill pattern |
| Inline in executor (current) | Extracted skill file | Extracting enables reuse across all agent types, reduces executor size, allows independent evolution |

**Installation:** No dependencies to install. Pure Markdown/prompt engineering.

## Architecture Patterns

### Recommended File Structure

```
skills/
  cortex/
    SKILL.md          # Main CORTEX skill (auto-trigger, classification + all frameworks)
agents/
  mz-executor.md      # Updated: references @skills/cortex/SKILL.md instead of inline CORTEX
skills/
  debug/
    SKILL.md           # Updated: CORTEX-aware debug depth in ROOT CAUSE phase
  go/
    SKILL.md           # No changes needed (already forwards cortex_enabled flag)
    executor.md        # Updated: references CORTEX skill for flag forwarding docs
```

### Pattern 1: Auto-Trigger Skill with Classification

**What:** The CORTEX skill auto-triggers on every task when `cortex_enabled` is true. It classifies the task domain, then conditionally applies thinking frameworks based on classification.

**When to use:** Every task execution when CORTEX is enabled in config.

**How it works in the executor flow:**
1. Executor receives `cortex_enabled: true` in `<execution_rules>`
2. Before each task, executor reads CORTEX skill protocol (already embedded inline or via @-reference)
3. Executor classifies task using heuristic table
4. Based on classification, executor applies the appropriate framework blocks
5. Framework output appears inside `<details>` collapsible blocks before task execution

**Key constraint:** The CORTEX skill cannot be a standalone invocable skill (like `/mz:debug`). It is a protocol reference file consumed by the executor. The skill frontmatter should have `disable-model-invocation: true` or be structured as an auto-trigger reference (no `/mz:cortex` command).

### Pattern 2: Framework Block Templates

**What:** Each thinking framework has a structured XML block template with specific required fields. Templates vary by framework -- some are rigid (Issue Tree), others are flowing (First Principles).

**Templates for each framework (verified from untools.co):**

#### Challenge Block (Complicated+ tasks) -- CORTEX-01

```xml
<details>
<summary>CORTEX -> {domain} | {signals} | Applying: {framework list}</summary>

<challenge domain="{complicated|complex}">
INVERSION (Pre-mortem):
  1. "This fails when {specific scenario 1}"
  2. "This fails when {specific scenario 2}"
  3. "This fails when {specific scenario 3}"

ASSUMPTIONS (Ladder of Inference):
  For each key assumption:
  - Data: {observable fact}
  - Interpretation: {what we read into the data}
  - Assumption: {inference we're making}
  - Status: {verified (checked in code/docs) | unverified (guessed)}

SECOND-ORDER (Consequence trace):
  If we do X:
  -> First-order: {immediate effect}
  -> Second-order: {what follows from that}
  -> Third-order: {what follows from that} (if relevant)

COUNTER: {strongest argument against this approach}
VERDICT: proceed | modify | reject
</challenge>

</details>
```

#### Complex Analysis Block (Complex tasks) -- CORTEX-02

```xml
<details>
<summary>CORTEX Complex Analysis</summary>

<complex-analysis>
FIRST-PRINCIPLES:
  Irreducible truths about this problem:
  1. {fundamental truth}
  2. {fundamental truth}
  3. {fundamental truth}

  Decomposition method: {Five Whys | Socratic Questioning}
  {Show the chain of questions that reached these fundamentals}

ABSTRACTION-LADDERING:
  WHY (move up): {What's the real problem behind the stated problem?}
  REFRAMED: {The problem restated at a higher abstraction level}
  HOW (move down): {What specific approaches address the reframed problem?}

ALTERNATIVES:
  1. {approach} -- tradeoffs: {pro/con}
  2. {approach} -- tradeoffs: {pro/con}
  3. {approach} -- tradeoffs: {pro/con}

SELECTED: {N} -- {rationale with evidence}
</complex-analysis>

</details>
```

#### Iceberg Analysis (Recurring-area tasks) -- CORTEX-03

```xml
<details>
<summary>CORTEX Iceberg Analysis: {area}</summary>

<iceberg area="{module/area name}">
EVENT: {What happened -- the surface symptom}
PATTERN: {Has this happened before? Evidence from SUMMARY.md, git history, or prior tasks}
STRUCTURE: {What system dynamics cause this pattern? Dependencies, coupling, tech debt, missing abstractions}
MENTAL-MODEL: {What assumption about this area keeps producing the pattern?}
LEVERAGE: {Where to intervene for a lasting fix, not just symptom treatment}
</iceberg>

</details>
```

#### Issue Tree + Ishikawa (Debug mode) -- CORTEX-04

The debug skill already has this. Enhancement is CORTEX-aware depth:

```xml
<issue-tree>
PROBLEM: {root problem statement}
+-- {Ishikawa category 1}: {hypothesis}
|   +-- {sub-cause}: {evidence for/against}
|   +-- {sub-cause}: {evidence for/against}
+-- {Ishikawa category 2}: {hypothesis}
|   +-- {sub-cause}: {evidence for/against}
+-- {Ishikawa category 3}: {hypothesis}
    +-- {sub-cause}: {evidence for/against}
LIKELY-ROOT: [{category}/{sub-cause}] -- {evidence}
</issue-tree>
```

**Software-adapted Ishikawa categories (already in debug skill):**

| Category | What to check |
|----------|--------------|
| Code | Logic errors, type mismatches, edge cases, off-by-one, null handling |
| Data | Schema mismatch, null/undefined values, encoding issues, malformed input |
| Environment | Node/runtime versions, OS differences, config mismatches, env vars |
| Dependencies | Version conflicts, breaking changes, missing packages, peer deps |
| Timing | Race conditions, async ordering, timeouts, event loop blocking |
| State | Stale cache, leaked state, initialization order, shared mutable state |

### Pattern 3: Concrete Classification Heuristics -- CORTEX-05

**What:** A multi-signal heuristic table that classifies task complexity. Not purely numeric -- concrete enough to be reproducible but flexible for edge cases.

**Recommended heuristic matrix:**

| Signal | Clear | Complicated | Complex | Chaotic |
|--------|-------|-------------|---------|---------|
| **LOC estimate** | <50 | 50-300 | >300 or new architecture | N/A (broken state) |
| **Files affected** | 1-2 | 3-5 | 6+ or new module structure | N/A |
| **New APIs/interfaces** | 0 | 1-2 internal | External API or new public interface | N/A |
| **Module scope** | Same module | 2-3 modules | 4+ modules or cross-system | N/A |
| **Pattern familiarity** | Well-known pattern, done before | 2+ valid patterns to choose from | No clear pattern, novel territory | N/A |
| **Existing test coverage** | Tests exist, minor modification | Tests need modification | No existing test patterns | Tests failing on unrelated code |
| **Side effects** | None | Localized, predictable | Distributed, hard to trace | Cascading failures |
| **External dependencies** | None new | Internal packages | External services, 3rd-party APIs | External service down/corrupt |

**Classification algorithm:**
1. Evaluate each signal independently
2. The task's domain is the HIGHEST domain that any signal triggers
3. Exception: Chaotic is only triggered by specific crisis signals (build broken, tests failing on unrelated code, external service down, data corruption, security incident) -- it cannot be triggered by quantitative thresholds alone
4. When signals conflict (e.g., low LOC but external API), explain the override: `CORTEX: Complicated -- 30 LOC but new external API integration elevates from Clear`

### Anti-Patterns to Avoid

- **Vague classification:** "This seems complicated" without citing specific signals. Always cite at least 2 concrete signals.
- **Framework theater:** Applying Inversion/Ladder/Second-Order mechanically without genuine reasoning. The frameworks should produce insights, not boilerplate.
- **Over-classifying:** Inflating complexity to justify elaborate framework output. Simple tasks should stay Clear even if the executor could produce impressive-looking analysis.
- **Under-classifying:** Downplaying complexity to avoid the work of framework analysis. If multiple signals point to Complicated, do not classify as Clear.
- **CORTEX noise on Simple tasks:** The user decision is explicit -- Simple tasks get NO visible CORTEX output. Not even a classification line.

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Thinking frameworks | Custom mental model taxonomy | untools.co framework definitions | Well-researched, community-tested, documented methodology |
| Recurring-area detection | Custom change-tracking database | SUMMARY.md scanning + git log | Already available in the execution flow, no new infrastructure |
| Classification persistence | Custom state file for classifications | Inline classification per-task, persisted in SUMMARY.md | Matches existing execution pattern, no new state management |
| Debug root-cause structure | New debugging methodology | Issue Tree (MECE) + Ishikawa | Already partially implemented in debug skill |

**Key insight:** The entire CORTEX enhancement is achievable through prompt engineering in Markdown files. No code changes, no new infrastructure, no new hooks. The config system already has the `quality.cortex` toggle. The executor already forwards the flag. The skill file pattern is established. This is a content authoring task, not a systems engineering task.

## Common Pitfalls

### Pitfall 1: Skill Reference Breaking Across Task Boundaries

**What goes wrong:** The CORTEX skill file is placed at `skills/cortex/SKILL.md` and the executor uses `@skills/cortex/SKILL.md` to reference it -- but @-references do not work across Task tool boundaries.

**Why it happens:** The Megazord architecture explicitly documents that "@file references do NOT work across Task tool boundaries" (executor.md line 147). The executor is spawned as a Task subagent.

**How to avoid:** The CORTEX protocol MUST be embedded inline in the `agents/mz-executor.md` file, OR the orchestrator (go skill) must read the CORTEX skill content and embed it in the Task prompt alongside the executor agent definition. The existing pattern embeds executor.md inline -- CORTEX content should follow the same pattern.

**Recommended approach:** Keep the authoritative CORTEX protocol in `skills/cortex/SKILL.md` for discoverability and editing, but the executor agent file (`agents/mz-executor.md`) must contain the full CORTEX protocol inline (duplicated from the skill). When CORTEX is updated, both files must be updated. Alternatively, the go skill orchestrator could read `skills/cortex/SKILL.md` and embed it as an additional `<cortex_protocol>` block in the Task prompt -- this avoids duplication but adds to prompt size. The user should decide which approach to use during planning.

**Warning signs:** Executor outputs "CORTEX: Clear" for every task regardless of complexity (the classification heuristic wasn't loaded).

### Pitfall 2: Context Budget Overflow

**What goes wrong:** The CORTEX skill content is too large, and embedding it in every executor Task prompt exceeds context limits or wastes budget on Simple tasks.

**Why it happens:** Eight frameworks with detailed templates, a heuristic matrix, and protocol instructions can easily exceed 2000-3000 tokens.

**How to avoid:** Structure the skill file with a compact classification section at the top (the heuristic table and one-line classification protocol) and framework details below. The orchestrator can embed only the classification section for Simple-likely tasks, and the full protocol for Complicated+ tasks. Alternatively, accept the fixed cost -- 2-3K tokens per executor invocation is acceptable if the analysis quality justifies it.

**Warning signs:** Executor responses are truncated or miss tasks at the end of the plan.

### Pitfall 3: Iceberg Model False Positives

**What goes wrong:** The Iceberg Model triggers on every task that touches a previously-modified file, flooding output with unnecessary systems analysis.

**Why it happens:** Almost every file in a codebase has been modified before. A naive "was this file in a previous SUMMARY?" check triggers constantly.

**How to avoid:** The trigger should be specifically: the file/module was **flagged as problematic** in a prior SUMMARY (mentioned in "Deviations from Plan", "Issues Encountered", or "Deferred Issues" sections) -- not merely listed as modified. This distinguishes "recurring problems" from "normal development iteration."

**Warning signs:** Every task in a phase triggers Iceberg Analysis even for routine file modifications.

### Pitfall 4: Debug Skill CORTEX Integration Confusion

**What goes wrong:** The debug skill and the executor both try to apply Issue Tree + Ishikawa, producing duplicate analysis or conflicting structures.

**Why it happens:** CORTEX-04 requires Issue Tree + Ishikawa in debug mode, but the debug skill already has these frameworks embedded. The executor's CORTEX classification also runs when debugging.

**How to avoid:** Clear ownership boundary: (a) When `/mz:debug` is invoked manually, the debug skill owns the analysis -- CORTEX classification is NOT applied separately (the debug skill has its own systematic methodology). (b) When debugging happens during execution (executor encounters a bug and applies auto-fix deviation rules), the executor's CORTEX classification governs. (c) The debug skill's existing Issue Tree + Ishikawa in Step 5 IS the CORTEX-04 implementation -- it just needs to be explicitly labeled as such and made conditional on complexity.

**Warning signs:** Same Issue Tree appears twice in output (once from CORTEX, once from debug skill).

### Pitfall 5: Executor Agent File Bloat

**What goes wrong:** Moving all CORTEX content into `agents/mz-executor.md` makes the file enormous (it's already 671 lines) and costly to embed in every Task prompt.

**Why it happens:** The executor handles TDD protocol, review protocol, commit protocol, deviation rules, teammate mode, CORTEX classification, challenge blocks, complex analysis, AND iceberg model -- all inline.

**How to avoid:** Two options: (a) Accept the size and embed the full executor -- the CORTEX section is ~150 lines, bringing total to ~820 lines. (b) Split executor into a core file + CORTEX reference file, where the orchestrator conditionally embeds the CORTEX reference only when `cortex_enabled: true`. Option (b) is cleaner but adds orchestrator complexity. User should decide during planning.

## Code Examples

Since this phase is pure prompt engineering (Markdown files, no TypeScript), the "code examples" are template structures.

### Classification Output (executor outputs this before each task)

```
CORTEX -> Clear -- 1 file, 20 LOC, established pattern
```

```
CORTEX -> Complicated | 4 files, ~150 LOC, new internal API, 2 valid patterns | Applying: Inversion + Ladder of Inference + Second-Order
```

```
CORTEX -> Complex | 8 files, new module structure, external API, no existing test patterns | Applying: First Principles + Abstraction Laddering + Inversion + Ladder + Second-Order
```

### Collapsible Output (user sees only the summary line)

```markdown
<details>
<summary>CORTEX -> Complicated | 3 files, known pattern, 1 new interface | Applying: Inversion + Ladder of Inference</summary>

<challenge domain="complicated">
INVERSION (Pre-mortem):
  1. "This fails when the new interface breaks backward compatibility with existing callers"
  2. "This fails when the test suite doesn't cover the new edge case introduced by the interface change"
  3. "This fails when a downstream module expects the old return type"

ASSUMPTIONS (Ladder of Inference):
  - Data: The current callers use method X with return type Y
  - Interpretation: All callers can be updated to the new interface simultaneously
  - Assumption: No external consumers depend on the old interface
  - Status: unverified -- need to check for external usage

SECOND-ORDER (Consequence trace):
  If we add the new interface:
  -> First-order: Callers must be updated to use new method signature
  -> Second-order: Tests for those callers must also be updated
  -> Third-order: Any mocks of this interface in other test files become stale

COUNTER: The existing interface could be extended instead of replaced, avoiding breaking changes entirely.
VERDICT: proceed -- the new interface is cleaner and the breaking change is internal
</challenge>

</details>
```

### CORTEX-Aware Debug Depth (debug skill enhancement)

```markdown
### Issue Tree Decomposition

**Activation:** Apply Issue Tree + Ishikawa MECE decomposition when the issue is NOT trivially obvious (i.e., the stack trace does not directly point to a single-line fix with obvious cause).

**Skip condition:** If the root cause is immediately apparent from the error message and stack trace (e.g., "Cannot read property 'x' of undefined at line 42"), proceed directly to the investigation without formal Issue Tree construction. Note: "Root cause: obvious from stack trace -- skipping formal decomposition."
```

## State of the Art

| Old Approach (current) | New Approach (Phase 14.1) | Impact |
|------------------------|--------------------------|--------|
| CORTEX protocol inline in `agents/mz-executor.md` | Dedicated `skills/cortex/SKILL.md` + updated executor reference | Discoverability, maintainability, independent evolution |
| Generic "3 pre-mortem scenarios" | Named Inversion framework with explicit "This fails when..." pattern from untools.co | More structured, reproducible pre-mortem analysis |
| "Assumption chain" in challenge block | Named Ladder of Inference with Data->Interpretation->Assumption->Status chain from untools.co | Catches specific assumption jumps, marks verified vs unverified |
| "2 consequences beyond immediate" | Named Second-Order Thinking with "And then what?" cascade from untools.co | More systematic consequence tracing |
| Ad-hoc "mini-brainstorm" for Complex | First Principles decomposition + Abstraction Laddering (why/how) from untools.co | Structured decomposition before generating alternatives |
| Iceberg block with no trigger definition | Iceberg Model with specific trigger: SUMMARY.md "Deviations/Issues/Deferred" mentions | Avoids false positives, targets recurring problem areas |
| Issue Tree + Ishikawa in debug (always) | CORTEX-aware conditional depth (skip for trivial bugs) | Reduces overhead on obvious fixes |
| LOC-only heuristic table | Multi-signal heuristic matrix with 8 dimensions | More reproducible classification with qualitative override |

## Open Questions

1. **CORTEX skill embedding strategy**
   - What we know: @-references don't work across Task boundaries. The executor must receive CORTEX content inline.
   - What's unclear: Should the CORTEX protocol be duplicated in `agents/mz-executor.md` (simple but maintenance burden), or should the orchestrator read `skills/cortex/SKILL.md` and embed it as a separate `<cortex_protocol>` block (clean but adds orchestrator logic)?
   - Recommendation: The orchestrator already reads the executor agent file and embeds it. Adding a second file read for `skills/cortex/SKILL.md` follows the same pattern. This keeps the authoritative content in one place. The planner should decide.

2. **Context budget impact**
   - What we know: The executor prompt already includes agent definition (~670 lines), plan content, config, and optionally reviewer definition. Adding CORTEX protocol adds ~150-200 lines.
   - What's unclear: Whether the cumulative prompt size causes context pressure on longer plans with many tasks.
   - Recommendation: Accept the fixed cost. 150-200 lines (~2-3K tokens) is small relative to the typical plan content. If needed, the orchestrator could conditionally omit CORTEX when `cortex_enabled: false` (it already does -- the section is simply not in the executor when disabled).

3. **CORTEX skill auto-trigger mechanism**
   - What we know: The user said "auto-trigger" and "no additional hooks needed." Existing skills trigger via `/mz:` commands or via agent protocol references.
   - What's unclear: The term "auto-trigger" in the skill context means the skill activates automatically as part of the executor flow (not invoked manually). This is different from a manual `/mz:cortex` command.
   - Recommendation: The CORTEX skill file should have `disable-model-invocation: true` in frontmatter (no slash command) and be a reference protocol consumed by the executor during task execution. The "auto-trigger" is the executor reading and applying the CORTEX protocol before each task when `cortex_enabled: true`.

## Sources

### Primary (HIGH confidence)

- **untools.co** -- All eight framework definitions verified:
  - [Inversion](https://untools.co/inversion/) -- Pre-mortem method, 3-step process (identify worst outcome, analyze reasons, reverse-engineer solutions)
  - [Ladder of Inference](https://untools.co/ladder-of-inference/) -- 7 rungs from data to action (Chris Argyris)
  - [Second-Order Thinking](https://untools.co/second-order-thinking/) -- "And then what?" cascade, 10/10/10 timeline method
  - [First Principles](https://untools.co/first-principles/) -- Decompose + Reconstruct, Five Whys + Socratic Questioning
  - [Abstraction Laddering](https://untools.co/abstraction-laddering/) -- Why (up) / How (down) reframing
  - [Iceberg Model](https://untools.co/iceberg-model/) -- 4 layers: Events, Patterns, Structures, Mental Models
  - [Issue Trees](https://untools.co/issue-trees/) -- MECE decomposition, Problem trees (Why?) and Solution trees (How?)
  - [Ishikawa Diagram](https://untools.co/ishikawa-diagram/) -- 6 cause categories, 4-step root cause analysis

### Secondary (MEDIUM confidence)

- **Megazord codebase** -- Direct file inspection of:
  - `agents/mz-executor.md` -- Current CORTEX implementation (classification table, challenge block, complex analysis, iceberg, pushback mandate)
  - `skills/debug/SKILL.md` -- Current Issue Tree + Ishikawa implementation in ROOT CAUSE phase
  - `skills/go/SKILL.md` -- CORTEX flag forwarding from config
  - `skills/go/executor.md` -- CORTEX flag documentation
  - `src/lib/config.ts` -- `quality.cortex` boolean in config schema, preset profiles
  - `.claude-plugin/plugin.json` -- Plugin manifest structure
  - `hooks/hooks.json` -- Current hook configuration (PreToolUse for ownership enforcement only)

### Tertiary (LOW confidence)

None -- all findings verified from primary or secondary sources.

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH -- All files are existing Markdown/prompt engineering, no external dependencies
- Architecture: HIGH -- Patterns directly observed in the codebase (skill file convention, executor embedding, config forwarding)
- Framework definitions: HIGH -- All eight frameworks verified from untools.co official content
- Pitfalls: MEDIUM -- Based on architectural analysis of the Task boundary limitation (documented) and context budget estimates (approximated)

**Research date:** 2026-02-20
**Valid until:** 2026-03-20 (stable domain -- thinking frameworks don't change, Megazord architecture is under author control)
