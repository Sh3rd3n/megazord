---
phase: 05-code-review-and-verification
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - agents/mz-reviewer.md
  - agents/mz-executor.md
  - skills/go/SKILL.md
  - skills/go/executor.md
autonomous: true
requirements: [QUAL-01]

must_haves:
  truths:
    - "A reviewer agent definition exists that performs two-stage review: spec compliance then code quality"
    - "The reviewer produces two separate reports with three severity levels: critical, warning, info"
    - "Spec compliance findings cite the specific plan task or requirement not satisfied"
    - "Architectural pushback from the reviewer is advisory only (warning/info), never critical"
    - "The executor agent spawns a reviewer subagent after each task commit when review is enabled"
    - "On critical findings, the executor auto-fixes and re-reviews up to a retry limit (max 3 total passes)"
    - "After the retry limit, unresolved critical findings are logged and execution continues"
    - "When review is disabled in config, the executor skips review entirely"
    - "The /mz:go orchestrator passes review_enabled flag to the executor via execution_rules"
    - "Review reports are persisted as markdown files in the phase directory"
  artifacts:
    - path: "agents/mz-reviewer.md"
      provides: "Two-stage code review agent definition with spec compliance and code quality protocols"
      min_lines: 120
    - path: "agents/mz-executor.md"
      provides: "Updated executor with review protocol section integrated into per-task flow"
      min_lines: 200
    - path: "skills/go/SKILL.md"
      provides: "Updated /mz:go skill that reads review config and passes review_enabled flag to executor"
      min_lines: 250
    - path: "skills/go/executor.md"
      provides: "Updated execution protocol documenting review integration point and reviewer spawning"
      min_lines: 60
  key_links:
    - from: "agents/mz-executor.md"
      to: "agents/mz-reviewer.md"
      via: "Executor reads reviewer agent definition and embeds in Task prompt when spawning reviewer"
      pattern: "agents/mz-reviewer.md"
    - from: "skills/go/SKILL.md"
      to: "agents/mz-executor.md"
      via: "Orchestrator passes review_enabled flag in execution_rules based on config.quality.review"
      pattern: "review_enabled"
    - from: "skills/go/executor.md"
      to: "agents/mz-reviewer.md"
      via: "Documents the reviewer spawning pattern for the executor"
      pattern: "mz-reviewer"
---

<objective>
Create the reviewer agent definition and integrate the two-stage code review into the execution pipeline. The reviewer performs spec compliance and code quality checks on each task's commit. The executor agent gains a review protocol that spawns the reviewer subagent after each task when review is enabled in config. The /mz:go orchestrator is updated to read the review config setting and pass it to executors.

Purpose: This is the first quality gate in Megazord -- automated code review that catches spec drift and quality issues before tasks are considered complete. The reviewer is a separate subagent from the executor, providing "fresh eyes" on the code. The review-fix loop (auto-fix on critical findings, retry limit, escalation) ensures quality without blocking execution indefinitely.

Output: `agents/mz-reviewer.md`, updated `agents/mz-executor.md`, updated `skills/go/SKILL.md`, updated `skills/go/executor.md`
</objective>

<execution_context>
@/Users/sh3rd3n/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sh3rd3n/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@agents/mz-executor.md
@skills/go/SKILL.md
@skills/go/executor.md
@skills/init/design-system.md
@.planning/megazord.config.json
@.planning/phases/05-code-review-and-verification/05-RESEARCH.md
@.planning/phases/04-subagent-execution-and-atomic-commits/04-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create reviewer agent definition</name>
  <files>
agents/mz-reviewer.md
  </files>
  <action>
Create `agents/mz-reviewer.md` as a dedicated two-stage code review agent. This agent is spawned by the executor subagent via the Task tool after each task commit. It follows the established agent definition pattern from `agents/mz-executor.md` (role, input, process, output sections).

Structure the agent definition with these sections:

**# Megazord Code Reviewer**

**## Your Objective**
Perform a two-stage review of a single task's changes: (1) spec compliance, (2) code quality. Produce two separate reports with findings classified as critical, warning, or info. Write the review report to disk.

**## Input**
You receive embedded inline in the Task prompt:
- `<task_definition>`: The specific task block from the PLAN.md that was just executed (name, files, action, verify, done)
- `<diff>`: The git diff of the task commit (`git diff HEAD~1 HEAD`)
- `<affected_files>`: Full content of each file modified by the task
- `<plan_requirements>`: Requirement IDs and descriptions from the plan frontmatter
- `<review_rules>`: Phase/plan/task numbers, report path, severity rules

**## Stage 1: Spec Compliance Review**
Check whether the implementation satisfies the plan task specification:
1. Does the diff implement everything described in `<action>`?
2. Are all files listed in `<files>` created/modified?
3. Do the changes satisfy `<done>` criteria?
4. If requirements are listed, does the implementation address them?

For each finding, cite the specific plan task element or requirement ID. Format:
```markdown
### Finding {N}: {title}
- **Severity:** critical | warning | info
- **Requirement:** {plan task element or requirement ID}
- **Issue:** {description of what's missing or wrong}
- **Suggestion:** {specific fix recommendation}
```

**## Stage 2: Code Quality Review**
Check code quality of the changes (review the diff AND the full affected files for context):
1. Error handling: Are errors caught and handled appropriately?
2. Input validation: Are inputs validated before use?
3. Type safety: Are types used correctly (no `any`, proper nullability)?
4. Naming: Are names descriptive and consistent with project conventions?
5. Patterns: Does the code follow established project patterns?
6. Duplication: Is there unnecessary duplication?
7. Edge cases: Are edge cases handled?
8. Security: Any obvious security issues?

For each finding, include file path and line reference. Format:
```markdown
### Finding {N}: {title}
- **Severity:** critical | warning | info
- **File:** {path}:{line}
- **Issue:** {description}
- **Suggestion:** {fix recommendation}
```

**## Severity Levels**
- **critical**: Blocks task completion. Must be fixed before proceeding.
  Examples: missing required functionality, broken imports, security vulnerability, data loss risk, spec requirement not implemented, broken types that prevent compilation.
- **warning**: Recommended fix. Should be addressed but doesn't block.
  Examples: missing error handling, inconsistent naming, potential bug, missing edge case handling, suboptimal pattern usage.
- **info**: Informational. Good to know, no action required.
  Examples: style suggestion, alternative approach note, documentation opportunity, minor optimization.

**## Architectural Pushback**
You CAN flag structural concerns as warning or info. You CANNOT flag them as critical. The architectural approach was decided at planning time. Your pushback is advisory only.

**## Report Persistence**
Write the review report to the path specified in `<review_rules>` using the Write tool. The report format:

```markdown
---
phase: {phase-slug}
plan: {plan_number}
task: {task_number}
reviewed: {ISO timestamp}
status: passed | issues_found
spec_findings: {count}
quality_findings: {count}
critical: {count}
warnings: {count}
info: {count}
---

# Review: Phase {X} Plan {Y} Task {Z}

## Spec Compliance

{findings or "No spec compliance issues found."}

## Code Quality

{findings or "No code quality issues found."}

## Summary

| Metric | Count |
|--------|-------|
| Spec findings | {N} |
| Quality findings | {N} |
| Critical | {N} |
| Warnings | {N} |
| Info | {N} |

**Status:** {passed | issues_found}
```

**## Large Diff Handling**
If the diff exceeds approximately 300 lines, focus on the diff content and skip embedding full affected files. The diff alone is sufficient for both spec compliance and quality review in most cases. Note in the report if full file context was not available.

**## Return Format**
Return this exact structure when done:

```markdown
## REVIEW COMPLETE

**Task:** {phase}-{plan} Task {N}
**Status:** passed | issues_found
**Critical:** {count}
**Warnings:** {count}
**Info:** {count}

### Spec Compliance
{summary of findings or "No issues found."}

### Code Quality
{summary of findings or "No issues found."}
```

**## Rules**
- Do NOT fix any code -- you review only, the executor handles fixes
- Do NOT update STATE.md, ROADMAP.md, or any project state files
- ALWAYS write the review report to the path in `<review_rules>` using the Write tool
- ALWAYS use bun/bunx for any JavaScript/TypeScript operations
- Keep reviews focused: only review changes in the diff, not pre-existing code
- Architectural concerns are NEVER critical severity
  </action>
  <verify>
Verify agents/mz-reviewer.md exists and contains: "Megazord Code Reviewer", "Stage 1: Spec Compliance", "Stage 2: Code Quality", "Severity Levels" (critical, warning, info), "Architectural Pushback" (advisory only), "REVIEW COMPLETE" return format, report persistence section. Must be at least 120 lines.
  </verify>
  <done>
agents/mz-reviewer.md is a complete two-stage code review agent definition that a Task tool subagent can follow to review a task commit for spec compliance and code quality, produce findings with three severity levels, persist a review report to disk, and return a structured result. Architectural pushback is advisory only. Spec findings cite specific plan tasks/requirements.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate review protocol into executor agent and /mz:go orchestrator</name>
  <files>
agents/mz-executor.md
skills/go/SKILL.md
skills/go/executor.md
  </files>
  <action>
**1. Update `agents/mz-executor.md`** -- Add a "Review Protocol" section after the existing "Deviation Rules" section and before "Summary Creation". This integrates per-task review into the executor's flow.

Add this new section:

**## Review Protocol**

After each task commit, check the review configuration in `<execution_rules>`.

### If review is enabled (review_enabled: true):

1. Get the diff of the task commit:
   ```bash
   DIFF=$(git diff HEAD~1 HEAD)
   ```

2. Get the list of affected files from the task's `<files>` section.

3. Read each affected file's full content using the Read tool.

4. Read `agents/mz-reviewer.md` using the Read tool.

5. Spawn reviewer via Task tool:
   - `subagent_type`: `"general-purpose"`
   - `description`: `"Review Phase {phase}-{plan} Task {N}: {task name}"`
   - Compose prompt with:
     ```
     <agent_role>
     {content of agents/mz-reviewer.md}
     </agent_role>

     <task_definition>
     {the specific <task> block from the PLAN.md that was just executed}
     </task_definition>

     <diff>
     {output of git diff HEAD~1 HEAD}
     </diff>

     <affected_files>
     {full content of each file modified by the task -- skip if diff exceeds 300 lines}
     </affected_files>

     <plan_requirements>
     {requirement IDs and descriptions from the plan frontmatter}
     </plan_requirements>

     <review_rules>
     - Phase: {phase_number}
     - Plan: {plan_number}
     - Task: {task_number}
     - Phase directory: {phase_dir}
     - Report path: {phase_dir}/{padded}-{plan}-REVIEW-T{task_num}.md
     - Severity levels: critical (blocks), warning (recommended), info (informational)
     - Two separate reports: spec compliance + code quality
     - Spec findings MUST cite plan task or requirement
     - Architectural concerns are warning/info only, never critical
     </review_rules>
     ```

6. Parse the structured result (look for `## REVIEW COMPLETE`).

7. Handle findings:
   - **No critical findings (status: passed):** Log review summary, continue to next task.
   - **Critical findings (attempt 1 or 2):**
     a. Fix each critical issue following Deviation Rule 1 (auto-fix bugs) or Rule 2 (auto-add missing)
     b. Stage fixed files: `git add {files}`
     c. Amend the commit: `git commit --amend --no-edit`
     d. Re-spawn reviewer for the amended diff (repeat from step 1)
   - **Critical findings (attempt 3 -- final):**
     a. Log remaining critical findings under "Unresolved Review Findings" in SUMMARY.md
     b. Continue to next task (escalation to orchestrator)

8. Persist review report:
   The reviewer writes the report to `{phase_dir}/{padded}-{plan}-REVIEW-T{task_num}.md` as part of its execution. Verify the file exists after the reviewer completes.

### If review is disabled (review_enabled: false):

Skip review entirely. Do not spawn reviewer. Do not log anything about review.

### Review retry limit

Maximum 2 re-reviews per task (3 total review passes including initial). After limit: log remaining findings in SUMMARY.md, continue to next task.

Also update the **Summary Creation** section to include review findings: add "Review Findings" as an optional section in SUMMARY.md. If any task had review findings (warnings, info, or unresolved criticals), include a summary table. If all tasks passed review cleanly, note "All tasks passed code review."

Also update the executor's **Execution Flow** step 3 to insert the review step after the commit:
- After step 3.f (record commit hash), add: 3.g. If review_enabled in execution_rules, run Review Protocol.

**2. Update `skills/go/SKILL.md`** -- Modify the orchestrator to read the review config and pass it to executors.

In **Step 2: Load Context and Validate**, after reading megazord.config.json, extract the review setting:
```
Determine review_enabled:
- If config.quality.review === "auto": review_enabled = true
- If config.quality.review === "manual": review_enabled = true (review runs, but critical findings are reported to user instead of auto-fixed)
- If config.quality.review === "off": review_enabled = false

If review_enabled is false, display a one-time notice:
> Note: Code review is disabled (quality.review: "off"). Tasks will not be reviewed.
```

In **Step 5: Execute Waves**, when composing the Task prompt's `<execution_rules>` section, add the review configuration:
```
<execution_rules>
... (existing rules) ...
- Review enabled: {true|false}
- Review mode: {auto|manual} (only if review_enabled is true)
</execution_rules>
```

Also in Step 5, after reading `agents/mz-executor.md` content (step 3 of pre-spawn), add:
- If review_enabled: also read `agents/mz-reviewer.md` content. Embed it in the Task prompt inside `<reviewer_agent>` tags so the executor has it available for spawning the reviewer without needing to read from disk.

Update the prompt structure to include:
```
<reviewer_agent>
{content of agents/mz-reviewer.md -- only included if review_enabled}
</reviewer_agent>
```

In **Step 7: Post-Execution Summary**, if any plan's SUMMARY.md mentions "Unresolved Review Findings", display a warning:
```
> Warning: Some tasks have unresolved review findings.
  Run /mz:review for manual review, or check the SUMMARY.md files for details.
```

**3. Update `skills/go/executor.md`** -- Add documentation about the review integration point.

Add a new section "## Review Integration" after the existing "Parallel Execution" section:

**## Review Integration**

When code review is enabled in config (`quality.review: "auto"` or `"manual"`), the executor performs a review cycle after each task commit.

| Responsibility | Owner |
|---------------|-------|
| Spawn reviewer subagent | Executor |
| Perform two-stage review | Reviewer |
| Write review report | Reviewer |
| Auto-fix critical findings | Executor |
| Re-spawn reviewer after fix | Executor |
| Log unresolved findings | Executor |
| Display review warnings | Orchestrator |

The reviewer agent definition is pre-loaded by the orchestrator and passed to the executor in `<reviewer_agent>` tags. The executor does not need to read it from disk.

### Review Prompt Structure

```
<agent_role>
{Content of agents/mz-reviewer.md}
</agent_role>

<task_definition>
{The specific task block that was just executed}
</task_definition>

<diff>
{git diff HEAD~1 HEAD}
</diff>

<affected_files>
{Full content of modified files -- omit if diff > 300 lines}
</affected_files>

<plan_requirements>
{Requirement IDs from plan frontmatter}
</plan_requirements>

<review_rules>
{Phase, plan, task numbers, report path, severity rules}
</review_rules>
```

### Review Modes

| Config Value | Behavior |
|-------------|----------|
| `"auto"` | Review runs, critical findings auto-fixed, retry up to 3 passes |
| `"manual"` | Review runs, critical findings reported to user (not auto-fixed) |
| `"off"` | No review, one-time notice displayed by orchestrator |
  </action>
  <verify>
1. agents/mz-executor.md contains a "Review Protocol" section with: reviewer spawning via Task tool, handling for critical/warning/info findings, retry limit (3 total passes), review_enabled conditional
2. skills/go/SKILL.md reads config.quality.review, sets review_enabled, passes it in execution_rules, displays one-time notice when review is off, reads and embeds agents/mz-reviewer.md when review is enabled
3. skills/go/executor.md has a "Review Integration" section documenting responsibility table and review prompt structure
4. agents/mz-executor.md Execution Flow step 3 includes review step after commit
5. No references to npm/npx (only bun/bunx)
  </verify>
  <done>
The executor agent integrates per-task code review into its execution flow: after each task commit, it spawns a reviewer subagent (when review is enabled), handles findings by severity, auto-fixes criticals with retry limit, and logs unresolved findings. The /mz:go orchestrator reads the review config, passes review_enabled to executors, pre-loads the reviewer agent definition, and warns about unresolved findings in the post-execution summary. The executor.md supporting file documents the review integration pattern.
  </done>
</task>

</tasks>

<verification>
1. agents/mz-reviewer.md exists with two-stage review (spec compliance + code quality), three severity levels, report persistence, structured return format (at least 120 lines)
2. agents/mz-executor.md has "Review Protocol" section with reviewer spawning, auto-fix on critical, retry limit of 3 passes, conditional on review_enabled
3. skills/go/SKILL.md reads config.quality.review, passes review_enabled in execution_rules, embeds reviewer agent when enabled, shows one-time notice when off
4. skills/go/executor.md documents review integration with responsibility table and prompt structure
5. No npm/npx references in any modified file
6. Reviewer agent specifies: review only (no fixing), spec findings cite requirements, architectural pushback is advisory only
7. Executor agent specifies: one commit per task (amend on fix), max 3 review passes, unresolved findings logged in SUMMARY
</verification>

<success_criteria>
When code review is enabled in config, the execution pipeline automatically reviews each task's commit through a two-stage process (spec compliance + code quality). The reviewer produces two separate reports with findings at three severity levels. Critical findings trigger auto-fix and re-review (up to 3 passes). The review report is persisted as a markdown file in the phase directory for audit trail. When review is disabled, the orchestrator shows a one-time notice and execution proceeds without review. This satisfies QUAL-01's requirement for automated two-stage code review when enabled in config.
</success_criteria>

<output>
After completion, create `.planning/phases/05-code-review-and-verification/05-01-SUMMARY.md`
</output>
